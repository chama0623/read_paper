# Speed/accuracy trade-offs for modern convolutional object detectorsを読んだメモ

## Abstractの翻訳
本論文の目的はアプリケーション, プラットフォームに応じた実行速度, メモリ使用量, 精度のバランスを達成する検出アーキテクチャを選択するガイドとなることである.このため最新の畳み込み物体認識システムにおいて, 精度と実行速度, メモリ使用量を交換する様々な方法を調査する. 近年数々の成功した物体認識システムが提案されてきたが, ベースとなる特徴抽出器が異なることや(例えばVGGNet, ResNet), 入力画像の解像度が異なること, 使用するハードウェアやソフトウェアプラットフォームが異なることから, 同一条件での比較は困難である. そこでFaster R-CNN, R-FCN, SSDの統一的な実装を示し, これらをメタアーキテクチャとみなして, 代替の特徴量抽出器を使用し入力画像のサイズを代表とする重要なパラメータを変化させたときに生じる実行速度と精度のトレードオフ曲線を追跡する. 実行速度とメモリ使用量が極めて重要な状況では, リアルタイムの処理速度を実現し, モバイルデバイスに展開可能な検出器を提案します. 他方精度が重要な状況では, COCO検出タスクで測定されたSoTAを達成する検出器を紹介する.

## 背景
(本論文は2017年に寄稿された論文であるため, それまでに提案された画像認識/物体認識アーキテクチャについて扱っている, またSSDは発表されたばかりだったらしい)  
近年，畳み込みニューラルネットワークにより物体認識はかなり発展してきた. そしてこれらの物体認識手法はGoogle Photos, Pinterest Visual Searchを代表とする顧客に提供するのに十分の性能を有している. しかし物体認識の実践者は構築したいアプリケーションにどんなアーキテクチャを用いるべきかを決めることが難しい. 物体認識の一般的な評価指標してmAPが用いられているが, 実際の画像認識システムでは実行時間やメモリ使用量も重要でありmAPだけでアーキテクチャの良し悪しを判断することはできない.
例えばモバイルデバイスでは小メモリでの実行, 自動運転ではリアルタイム実行が求められる. 他方サーバー再度で実行される画像認識システムは精度を重視しているが, スループット(実行速度)の制約もある. 画像認識コンペティションで優勝するような手法は精度のみに最適化されており, 実使用時の実行時間が非常に遅いアンサンブルやマルチクロップ手法を用いている.  
物体認識手法の論文は実行時間に関する詳細な議論が活発でないという問題もある(よく議論されているのはR-FCN, SSD, YOLO). さらにこれらの論文では, 達成したフレームレートが記述されているだけで, 実行速度と精度のトレードオフの全体像が述べられていない. このトレードオフはどんな特徴抽出器を使用するかや, 入力画像のサイズを代表とする要因に依存する.
→ これまでの提案手法論文は精度にスポットライトが当てられており, 実行速度やメモリ使用量に関する議論が不十分である.

## 目的
本論文では, 最新の物体認識システムの実行速度と精度のトレードオフを網羅的から公平な方法で評価する方法を探索する. 画像認識の分野では実行速度と精度のトレードオフを検証する方法が既存研究として存在するが, 物体認識は画像認識より複雑であるため, 物体認識に適した方法を考える必要がある. 複雑なモデルの例としてアンサンブルやマルチクロップを行う物体認識手法が存在するが, ここでは単一のモデル(入力から出力まで1つのネットワークを通す単純なモデル)を対象とし, それらのモデルのテスト時の性能に焦点を当てる. 学習時の時間は特に考慮しない.  
単一モデルに絞っても検出モデルは多数あり, それらすべてを調査するのは現実的ではない. ただし, 最先端のアプローチはある程度方法が共通している部分があるため, 統一的なモデルを実装して比較することができる. 本研究では特に注目されている手法であるFaster R-CNN, R-FCN, SSDのメタアーキテクチャを実装した. これらのアーキテクチャに共通する特徴は次の通りである.
- 単一の畳み込みネットワークで構成される
- 回帰と分類が同時に学習される 
- スライディングウィンドウ法を用いた予測を行っている

本論文の貢献は次の通りである.
- 最新の物体認識システムの構造と, 主要な物体認識システムの設計の類似点の比較
- TensorflowによりFaster R-CNN, R-FCN, SSDの柔軟で統一された実装を行い, メタアーキテクチャ, 特徴抽出器, 画像解像度を代表とするパラメータを変化させたときの精度, 実行速度のトレードオフを観測すること
- 知見: Faster R-CNNのproposal数を少なくすると, 精度を大きく損なうことなくSSDやR-FCNと競合可能な実行速度になる(高速化), SSDの性能なFaster R-CNN, R-FCNと比較して特徴検出器の品質に影響されにくい, 速度を犠牲にすることでしか精度を向上させることができないスイートスポットが存在すること
- これまでにないメタアーキテクチャと特徴抽出器の組み合わせでどのような学習を行ったのかの紹介

## 畳み込みニューラルネットワークを用いた物体認識手法の歴史・代表的なモデル
畳み込みニューラルネットワークに基づいた最初の現代的な取り組みが行われたのはR-CNN(2013)である.
R-CNNはILSVRC2012(画像認識コンペティション)で優勝したCNNを用いた画像認識モデルAlexNetに基づいて構築されている. R-CNNのアーキテクチャは次の通りである. このアーキテクチャは画像から大量の切り出しを行い, 重複する領域に対して複数回CNNを実行するため非常に低速であった.

1. 画像をSelective Search(SS)に入力し, 画像処理により領域提案(Region Proposal)を行う. これにより2000枚の領域候補(Region of Interest;RoI)が作成される.
2. 各RoIに対して3～6の処理を実行する.
3. RoIを固定のサイズに拡大・縮小する. 
4. 3で処理したRoIをCNN(ALexNetと同じ構造)に入力し, 特徴量マップ(Feature Map)を作成する.
5. 特徴量マップを2値分類SVMに入力し, ラベルを出力する. 
6. (必要であれば) Bounding Box Regressorを実行してBounding Boxの位置を調整する.
7. 3～6の処理で得られたオブジェクトにNon-Maximum Suppression;NMSを実行して, 重複する領域を取り除く

R-CNNの遅さを改善するため, Fast R-CNNが提案された. Fast R-CNNのアーキテクチャは次の通りである.(アーキテクチャ略) Fast R-CNNは画像の切り出しを途中で行うことで特徴抽出の計算負荷を軽量化し, 高速となった.  
R-CNNもFast R-CNNもSelective Searchによる領域提案に依存しており, これがボトルネックになっている(SSに2s, それ以外は0.3s程度). そこでニューラルネットワークにより領域提案が行えないか研究が行われた. 素の結果としてanchorと呼ばれる異なるスケールおよびアスペクト比のボックスの集合を, 画像上にオーバーレイ(重ね合わせる)ことが開発された. そしてモデルは各anchorに対して次の2つを予測するように学習が行われる. (LossはReg LossとClass Lossの2つを合わせたもの)
1. 各anchorに対するクラス予測
2. 各anchorをグランドトゥルース(正解のボックス)に適合させるための調整値

SSD, Faster R-CNN, R-FCNはオリジナルの論文では特定の特徴抽出器により実装されている. ここでは3つの物体認識アルゴリズムに用いる特徴抽出器を選択できるようにするために, それぞれのメタアーキテクチャを作成し, そこに特徴量抽出器を埋め込めるようにする. そしてそれらの手法をレビューする.  
**SSD**  
SSDは論文執筆時には発表されたばかりのアーキテクチャである. 筆者らはSSDのメタアーキテクチャをRPNによる領域提案とクラス分類の2段階の処理を必要としない, 単一のフィードフォワードネットワークを使用するものと定義づけた.  
**Faster R-CNN**  
Faster R-CNNは2段階で行われる. 処理手順を次に示す.  
1段階目(Region Proposal Network)  
画像をVGG16に通す. VGG16の中間レベル(ex. conv5)の特徴量を抽出する. これを特徴量マップと呼ぶ.

2段階目     
1. 特徴量マップにAnchorを適用して300個のproposalを得る.
2. 特徴量マップにproposalを射影する(特徴量マップの切り取り).
3. 各切り取れた特徴量マップを特徴抽出器に入力(ex.fc6, fc7)し, クラス分類とボックスの洗練(微調整)を行う.

**R-FCN**  
Faster R-CNNはFast R-CNNより1桁高速であるが, Anchorに対する処理は数百回しなければならない. そこでRegion-based Fully convolutional Networks(R-FCN)が提案された.
(後でまとめる)

## 実験方法


## 実験結果

## 結論
