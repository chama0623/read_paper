# R-CNN論文を読んだメモ

## Abstractの翻訳
PASCAL VOCデータセットで測定される物体認識の性能は近年頭打ちになってきている. 
最も良い性能の方法は複数の低レベルな画像特徴を高レベルのコンテキストと組み合わせる複雑なアンサンブルモデルである.
本論文では, VOC2012の最高成績からさらにmAPを30%以上向上させた単純で拡張性のある検出アルゴリズムを提案する(これによりmAPは53.3%を達成した).
提案するアプローチは2つの重要な洞察を組み合わせている. 一つ目は大規模な畳み込みニューラルネットワーク(CNN)をボトムアップな領域提案に使用し, 位置決めやセグメントを行うことである. 二つ目はラベル付きの学習データが乏しい場合に, 補助的なタスクで教師ありのpre-trainingを行い, その後でドメインに特化したfine-tuningを行うことで性能が大幅に向上することである.
このように領域提案とCNNを組み合わせた手法をRegions with CNN(R-CNN)と呼ぶことにする. 本論文ではさらにR-CNNと, 近年提案されたCNNに基づくsliding-window法による検出器であるOverFeatを比較する.
そしてこの結果ILSVRC2013の200クラス検出データセットにおいて, R-CNNがOverFeatを上回る性能であることを発見した.

## 背景
CNNは1980～90年代に研究が行われた. 1989年にはLeNet[1]と呼ばれるCNNアーキテクチャが手書き文字認識で成果をあげた.
しかし, 当時はデータ容量が乏しく大規模なデータセットを扱うことが難しかったこと, 計算リソースが潤沢でなかったためCNNのような多くのパラメータを持つモデルを扱うことが難しかったことから, SVMのような小規模データセットで良い性能がでるモデルが台頭した. 
このため～2011年の画像認識ではSIFTやHOGを代表とする局所的な画像特徴をベースとするモデルが用いられてきた. そのような中で2012年にKrizhevsky et al.[2]はCNNベースのアーキテクチャであるAlexNetを開発した. そしてAlexNetでILSVRC2012に参加し, エラー率16.4%(2位と10.8%の差)で優勝した.  
→ ILSVRC2012でブレイクスルーを起こしたCNNを物体認識でも取り込めないか?という問題を解決したのがR-CNN

## メモ
物体認識が画像認識と異なる点はオブジェクトの分類だけでなく, 位置を特定する必要があることである. これは回帰, sliding-window法や小規模なCNNによる方法が先行研究として提案されているがどれも良い成果をあげられていない. → region proposal(領域提案)を用いた手法を提案


## 参考文献
[1] Yann LeCun, et al., "Generalization and Network Design Strategies"  
[2] Krizhevsky, et al., "ImageNet Classification with Deep COnvolutional Neural Networks"